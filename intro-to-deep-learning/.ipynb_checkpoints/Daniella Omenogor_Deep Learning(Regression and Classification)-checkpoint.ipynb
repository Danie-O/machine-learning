{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c83c6ff",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60614178",
   "metadata": {},
   "source": [
    "### Import necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a326e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b644b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=500, n_features=10,\n",
    "                       noise=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8256c",
   "metadata": {},
   "source": [
    "We first import the necessary libraries such as `Scikit-learn`, `Numpy` and `Matplotlib.` We also generated a synthetic dataset from the Scikit-learn dataset library, which is a regression dataset with 500 instances and 10 attributes. We then separate the independent variable X and dependent variable y from the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096a643",
   "metadata": {},
   "source": [
    "### Data Preprocessing - apply StandardScaler to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4ce1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54f95f",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43f81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb834114",
   "metadata": {},
   "source": [
    "In this step, we split the dataset into training and testing sets. We keep `70%` of the dataset for training and `30%` for testing. We also set a random seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a6cde",
   "metadata": {},
   "source": [
    "### Implement a Linear Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a228b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LinearR = LinearRegression()\n",
    "LinearR.fit(X_train, y_train)\n",
    "y_pred = LinearR.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3bb8c2",
   "metadata": {},
   "source": [
    "Here, we import the Perceptron algorithm from Scikit-learn's linear_model library. We then instantiate the perceptron object and fit it to our training data. We use the trained model to predict the target variable on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56bef5d",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010e627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.9052902177417593\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0d078",
   "metadata": {},
   "source": [
    "In this step, we calculate the mean squared error between the predicted values and actual values. This will give us an idea of how well our model is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6ac84",
   "metadata": {},
   "source": [
    "### Plot the residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20183fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722819a",
   "metadata": {},
   "source": [
    "Finally, we plot the residual between the predicted and actual values to visualize the errors in our model. A good model will have residuals randomly scattered around zero.\n",
    "\n",
    "Overall, this code blocks above implement a linear regression algorithm for the generated dataset, evaluates its performance using mean squared error and plots the residual to visualize the errors. Other regression algorithms such as decision tree regression or random forest regression can also be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbf17f",
   "metadata": {},
   "source": [
    "# Neural Network (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "599a2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e32bc8",
   "metadata": {},
   "source": [
    "### Data Preprocessing - apply StandardScaler to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a360f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09faf6f1",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d446d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e9d08",
   "metadata": {},
   "source": [
    "In this step, we split the dataset into training and testing sets. We keep 70% of the dataset for training and 30% for testing. We also set a random seed for reproducibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2030c6",
   "metadata": {},
   "source": [
    "### Implement a neural network model with 2 hidden layers using Keras (activation function: ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ced5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), epochs=100,\n",
    "                    batch_size=32, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6514e",
   "metadata": {},
   "source": [
    "Here, I define a sequential neural network model using Keras. I have also added 2 dense layers with 64 neurons each which use the rectified linear unit (ReLU) activation function. A final dense layer with a single neuron is also added for output. Then, the model is compiled using the Adam optimizer and mean squared error (MSE) loss function.\n",
    "\n",
    "The parameters for fitting the training data include:\n",
    "- 100 epochs \n",
    "- batch size of 32 (for each epoch, we feed the data into the model by iterating through the data (X_train.shape[0] / 32) times\n",
    "\n",
    "We also evaluate the model on the testing data using the validation_data parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec06b08",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc058394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error:  44.803104400634766\n",
      "Testing Mean Squared Error:  75.55601501464844\n"
     ]
    }
   ],
   "source": [
    "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Training Mean Squared Error: \", mse_train)\n",
    "print(\"Testing Mean Squared Error: \", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2576b8",
   "metadata": {},
   "source": [
    "In this step, we calculate the mean squared error between the predicted values and actual values for both training and testing sets. This gives us an idea of how well our model is performing.\n",
    "\n",
    "As seen from the results, the model does not perform too well as the testing mean squared error is way over 50%. This shows that the model does not perform too well when predicting unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165459b0",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7403fd",
   "metadata": {},
   "source": [
    "1. Try different number of hidden layers, number of neurons and changing the activation function\n",
    "2. Plot the residual, training and testing.\n",
    "3. Report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832a6f4",
   "metadata": {},
   "source": [
    "### 1) Implement a neural network model with 3 hidden layers using Keras (activation function:ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46668d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), epochs=100,\n",
    "                    batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec83afd",
   "metadata": {},
   "source": [
    "Here, I define a sequential neural network model with 3 hidden layers as opposed to the previous model.\n",
    "The hidden layers consist of 128, 64 and 32 neurons respectively with each using the rectified linear unit (ReLU) activation function. There is also a final dense layer with a single neuron for output. The model is compiled using the Adam optimizer and mean squared error (MSE) loss function.\n",
    "\n",
    "The parameters for fitting the training data include:\n",
    "- 100 epochs \n",
    "- batch size of 32 (for each epoch, we feed the data into the model by iterating through the data (X_train.shape[0] / 32) times\n",
    "\n",
    "We also evaluate the model on the testing data using the validation_data parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc349fe",
   "metadata": {},
   "source": [
    "#### Evaluate the performance of the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e144f71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error:  13.234246253967285\n",
      "Testing Mean Squared Error:  42.14602279663086\n"
     ]
    }
   ],
   "source": [
    "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Training Mean Squared Error: \", mse_train)\n",
    "print(\"Testing Mean Squared Error: \", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9822d7",
   "metadata": {},
   "source": [
    "After adding an additional layer, and reducing the number of neurons in the second hidden layer from 64 to 32, the model's performance increased. This can be seen in the reduction of the mean squared error from *75.556* to *42.146*. This shows that by increasing the number of layers and gradually reducing the size of the hidden layers, the model performed better. \n",
    "\n",
    "The next implementation uses less hidden layers, but employs a more powerful activation function than the regular ReLU function: LeakyReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446168d",
   "metadata": {},
   "source": [
    "### 2) Implement a neural network model with 2 hidden layers using Keras (activation function: Leaky ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcfa59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LeakyReLU module and create a LeakyReLU instance\n",
    "from keras.layers import LeakyReLU\n",
    "leaky_relu = LeakyReLU(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "206f5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='leaky_relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='leaky_relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), epochs=100,\n",
    "                    batch_size=32, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed1026",
   "metadata": {},
   "source": [
    "Here, I define a sequential neural network model with 2 hidden layers as opposed to the previous model.\n",
    "The hidden layers consist of 64 neurons each and each of the layers uses the Leaky rectified linear unit (Leaky ReLU) activation function. There is also a final dense layer with a single neuron for output. The model is compiled using the Adam optimizer and mean squared error (MSE) loss function.\n",
    "\n",
    "The parameters for fitting the training data include:\n",
    "- 100 epochs \n",
    "- batch size of 32 (for each epoch, we feed the data into the model by iterating through the data (X_train.shape[0] / 32) times\n",
    "\n",
    "We also evaluate the model on the testing data using the validation_data parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46dc855",
   "metadata": {},
   "source": [
    "#### Evaluate the performance of the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7d8c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error:  22.729644775390625\n",
      "Testing Mean Squared Error:  42.680843353271484\n"
     ]
    }
   ],
   "source": [
    "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Training Mean Squared Error: \", mse_train)\n",
    "print(\"Testing Mean Squared Error: \", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ffda2a",
   "metadata": {},
   "source": [
    "After reducing the number of hidden layers and changing the activation function to the LeakyReLU function, the model's performance reduced slightly. This is rather surprising since we would expect the LeakyReLU function to perform better than the regular ReLU function used in the previous model. \n",
    "However, if we observe that the number of hidden layers was reduced, we can understand the reason for the reduction in the model's performance.\n",
    "\n",
    "The next implementation uses the same activation function (LeakyReLU) but adds an additional hidden layer. We shall observe if the LeakyReLU's performance increases with an increase in the number of hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764808a7",
   "metadata": {},
   "source": [
    "### 3) Implement a neural network model with 3 hidden layers using Keras (activation function: Leaky ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a331523",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = LeakyReLU(alpha=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27b8f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='leaky_relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='leaky_relu'))\n",
    "model.add(Dense(32, activation='leaky_relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), epochs=100,\n",
    "                    batch_size=32, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04b846",
   "metadata": {},
   "source": [
    "Here, I define a sequential neural network model with 3 hidden layers as opposed to the previous model.\n",
    "The hidden layers consist of 128, 64 and 32 neurons respectively with each using the Leaky rectified linear unit (Leaky ReLU) activation function. There is also a final dense layer with a single neuron for output. The model is compiled using the Adam optimizer and mean squared error (MSE) loss function.\n",
    "\n",
    "The parameters for fitting the training data include:\n",
    "- 100 epochs \n",
    "- batch size of 32 (for each epoch, we feed the data into the model by iterating through the data (X_train.shape[0] / 32) times\n",
    "\n",
    "We also evaluate the model on the testing data using the validation_data parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254706f7",
   "metadata": {},
   "source": [
    "#### Evaluate the performance of the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcb0250e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error:  3.4922749996185303\n",
      "Testing Mean Squared Error:  11.26406478881836\n"
     ]
    }
   ],
   "source": [
    "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Training Mean Squared Error: \", mse_train)\n",
    "print(\"Testing Mean Squared Error: \", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac40c4c",
   "metadata": {},
   "source": [
    "The results above confirm the fact that the more hidden layers, the better the performance of the model.\n",
    "We can see that the testing MSE shows a drastic reduction from 42.68 to 11.264, after the addition of just one hidden layer consisting of 32 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468c2a7",
   "metadata": {},
   "source": [
    "*Note: Leaky ReLU is an improvement over the ReLU activation function. It has all properties of ReLU, plus it will never have dying ReLU problem(a situation which occurs during training when some neurons effectively die, and stop outputting anything other than 0)*\n",
    "\n",
    "Follow this link for more information on Leaky ReLU: <a href=\"https://towardsdatascience.com/7-popular-activation-functions-you-should-know-in-deep-learning-and-how-to-use-them-with-keras-and-27b4d838dfe6\">(7 popular activation functions you should know in Deep Learning and how to use them with Keras and TensorFlow 2)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb138f2f",
   "metadata": {},
   "source": [
    "# Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922426f",
   "metadata": {},
   "source": [
    "### Import necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbaf1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fac8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d9352",
   "metadata": {},
   "source": [
    "In this step, we first import the necessary libraries such as Scikit-learn, Keras, Numpy and Matplotlib. We also load the Iris dataset from the Scikit-learn dataset library, which is a classification dataset with 150 instances and 4 attributes. We then separate the independent variable X and dependent variable y from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d2b26",
   "metadata": {},
   "source": [
    "### Data Preprocessing - apply StandardScaler to standardize the data and convert the target variable to categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c48d8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acf7c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b92650",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da7bf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547e379",
   "metadata": {},
   "source": [
    "In this step, we split the dataset into training and testing sets. We keep 70% of the dataset for training and 30% for testing. We also set a random seed for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef631658",
   "metadata": {},
   "source": [
    "### Implement a neural network model with 3 hidden layers using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12153680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 1s 63ms/step - loss: 1.0188 - accuracy: 0.4190 - val_loss: 0.9240 - val_accuracy: 0.5111\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9564 - accuracy: 0.5619 - val_loss: 0.8573 - val_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9038 - accuracy: 0.6857 - val_loss: 0.7934 - val_accuracy: 0.7778\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8500 - accuracy: 0.7238 - val_loss: 0.7360 - val_accuracy: 0.8222\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8023 - accuracy: 0.7810 - val_loss: 0.6820 - val_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7584 - accuracy: 0.7619 - val_loss: 0.6326 - val_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7139 - accuracy: 0.7810 - val_loss: 0.5898 - val_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6736 - accuracy: 0.7810 - val_loss: 0.5518 - val_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6378 - accuracy: 0.8000 - val_loss: 0.5189 - val_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6013 - accuracy: 0.8000 - val_loss: 0.4887 - val_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5682 - accuracy: 0.8095 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5326 - accuracy: 0.8190 - val_loss: 0.4346 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5029 - accuracy: 0.8095 - val_loss: 0.4107 - val_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4745 - accuracy: 0.8095 - val_loss: 0.3918 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4491 - accuracy: 0.8190 - val_loss: 0.3751 - val_accuracy: 0.8222\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4267 - accuracy: 0.8286 - val_loss: 0.3600 - val_accuracy: 0.8444\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4069 - accuracy: 0.8381 - val_loss: 0.3452 - val_accuracy: 0.8444\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3877 - accuracy: 0.8381 - val_loss: 0.3329 - val_accuracy: 0.8444\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3700 - accuracy: 0.8381 - val_loss: 0.3195 - val_accuracy: 0.8444\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3536 - accuracy: 0.8381 - val_loss: 0.3067 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3378 - accuracy: 0.8381 - val_loss: 0.2956 - val_accuracy: 0.8444\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3246 - accuracy: 0.8476 - val_loss: 0.2864 - val_accuracy: 0.8444\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3130 - accuracy: 0.8476 - val_loss: 0.2788 - val_accuracy: 0.8444\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3029 - accuracy: 0.8476 - val_loss: 0.2687 - val_accuracy: 0.8444\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2917 - accuracy: 0.8667 - val_loss: 0.2551 - val_accuracy: 0.8444\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2801 - accuracy: 0.8762 - val_loss: 0.2417 - val_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2705 - accuracy: 0.8857 - val_loss: 0.2290 - val_accuracy: 0.8889\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2612 - accuracy: 0.8952 - val_loss: 0.2189 - val_accuracy: 0.8889\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2517 - accuracy: 0.9143 - val_loss: 0.2079 - val_accuracy: 0.8889\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2445 - accuracy: 0.9333 - val_loss: 0.1974 - val_accuracy: 0.9111\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2374 - accuracy: 0.9333 - val_loss: 0.1880 - val_accuracy: 0.9556\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2304 - accuracy: 0.9429 - val_loss: 0.1791 - val_accuracy: 0.9556\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2228 - accuracy: 0.9429 - val_loss: 0.1727 - val_accuracy: 0.9556\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2148 - accuracy: 0.9429 - val_loss: 0.1652 - val_accuracy: 0.9556\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2083 - accuracy: 0.9429 - val_loss: 0.1633 - val_accuracy: 0.9333\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2011 - accuracy: 0.9429 - val_loss: 0.1564 - val_accuracy: 0.9333\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1952 - accuracy: 0.9429 - val_loss: 0.1472 - val_accuracy: 0.9556\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1879 - accuracy: 0.9429 - val_loss: 0.1413 - val_accuracy: 0.9556\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1836 - accuracy: 0.9429 - val_loss: 0.1371 - val_accuracy: 0.9556\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1773 - accuracy: 0.9524 - val_loss: 0.1269 - val_accuracy: 0.9778\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1700 - accuracy: 0.9524 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1654 - accuracy: 0.9429 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1605 - accuracy: 0.9429 - val_loss: 0.1025 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1547 - accuracy: 0.9429 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1477 - accuracy: 0.9429 - val_loss: 0.0930 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1411 - accuracy: 0.9524 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1393 - accuracy: 0.9429 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1347 - accuracy: 0.9429 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1280 - accuracy: 0.9429 - val_loss: 0.0785 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1220 - accuracy: 0.9524 - val_loss: 0.0737 - val_accuracy: 0.9778\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1186 - accuracy: 0.9524 - val_loss: 0.0720 - val_accuracy: 0.9778\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1150 - accuracy: 0.9524 - val_loss: 0.0685 - val_accuracy: 0.9778\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1133 - accuracy: 0.9524 - val_loss: 0.0648 - val_accuracy: 0.9778\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1073 - accuracy: 0.9524 - val_loss: 0.0619 - val_accuracy: 0.9778\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1032 - accuracy: 0.9619 - val_loss: 0.0591 - val_accuracy: 0.9778\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0993 - accuracy: 0.9619 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0966 - accuracy: 0.9714 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0941 - accuracy: 0.9714 - val_loss: 0.0520 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0912 - accuracy: 0.9714 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0886 - accuracy: 0.9714 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0863 - accuracy: 0.9714 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0848 - accuracy: 0.9714 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0835 - accuracy: 0.9619 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0830 - accuracy: 0.9619 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9714 - val_loss: 0.0547 - val_accuracy: 0.9778\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0769 - accuracy: 0.9714 - val_loss: 0.0576 - val_accuracy: 0.9778\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0752 - accuracy: 0.9810 - val_loss: 0.0526 - val_accuracy: 0.9778\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0741 - accuracy: 0.9714 - val_loss: 0.0487 - val_accuracy: 0.9778\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0711 - accuracy: 0.9810 - val_loss: 0.0439 - val_accuracy: 0.9778\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0712 - accuracy: 0.9714 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0715 - accuracy: 0.9714 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0697 - accuracy: 0.9714 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0673 - accuracy: 0.9810 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0662 - accuracy: 0.9810 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0660 - accuracy: 0.9810 - val_loss: 0.0374 - val_accuracy: 0.9778\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0649 - accuracy: 0.9810 - val_loss: 0.0350 - val_accuracy: 0.9778\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0334 - val_accuracy: 0.9778\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0630 - accuracy: 0.9905 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0639 - accuracy: 0.9810 - val_loss: 0.0327 - val_accuracy: 0.9778\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0592 - accuracy: 0.9714 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.0326 - val_accuracy: 0.9778\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0552 - accuracy: 0.9905 - val_loss: 0.0360 - val_accuracy: 0.9778\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0406 - val_accuracy: 0.9778\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.0302 - val_accuracy: 0.9778\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0567 - accuracy: 0.9714 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0575 - accuracy: 0.9714 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0528 - accuracy: 0.9905 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0503 - accuracy: 0.9905 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0499 - accuracy: 0.9810 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0497 - accuracy: 0.9905 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0479 - accuracy: 0.9905 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0488 - accuracy: 0.9810 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0480 - accuracy: 0.9905 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0476 - accuracy: 0.9905 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0474 - accuracy: 0.9905 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0478 - accuracy: 0.9905 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0468 - accuracy: 0.9905 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0464 - accuracy: 0.9905 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9810 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0464 - accuracy: 0.9810 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0448 - accuracy: 0.9810 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0444 - accuracy: 0.9905 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0441 - accuracy: 0.9905 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0440 - accuracy: 0.9905 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0445 - accuracy: 0.9905 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9905 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0452 - accuracy: 0.9905 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0440 - accuracy: 0.9810 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0444 - accuracy: 0.9810 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0432 - accuracy: 0.9905 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0424 - accuracy: 0.9905 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0416 - accuracy: 0.9905 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0407 - accuracy: 0.9905 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0425 - accuracy: 0.9905 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 0.9905 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0405 - accuracy: 0.9905 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0398 - accuracy: 0.9810 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0443 - accuracy: 0.9810 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0444 - accuracy: 0.9810 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0420 - accuracy: 0.9810 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9905 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0402 - accuracy: 0.9905 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0385 - accuracy: 0.9905 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0374 - accuracy: 0.9810 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0415 - accuracy: 0.9810 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0398 - accuracy: 0.9810 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0371 - accuracy: 0.9810 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0392 - accuracy: 0.9905 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0381 - accuracy: 0.9905 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0390 - accuracy: 0.9905 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0414 - accuracy: 0.9810 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0417 - accuracy: 0.9810 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0375 - accuracy: 0.9810 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0390 - accuracy: 0.9810 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0394 - accuracy: 0.9810 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 0.9810 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0354 - accuracy: 0.9810 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0362 - accuracy: 0.9810 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0360 - accuracy: 0.9810 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0345 - accuracy: 0.9905 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0343 - accuracy: 0.9905 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0343 - accuracy: 0.9905 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0335 - accuracy: 0.9905 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0332 - accuracy: 0.9810 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 0.9810 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0353 - accuracy: 0.9810 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9810 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0359 - accuracy: 0.9810 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0361 - accuracy: 0.9810 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0320 - accuracy: 0.9810 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0323 - accuracy: 0.9905 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9810 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.9810 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0309 - accuracy: 0.9810 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0305 - accuracy: 0.9810 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0296 - accuracy: 0.9810 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0308 - accuracy: 0.9810 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9810 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9905 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9905 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0225 - accuracy: 0.9905 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9905 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9905 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9905 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0215 - accuracy: 0.9905 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9905 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9905 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9905 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9905 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9905 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 0.9905 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9905 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9905 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9905 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9905 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0182 - accuracy: 0.9905 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 0.9905 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0177 - accuracy: 0.9905 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0192 - accuracy: 0.9905 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0199 - accuracy: 0.9905 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0182 - accuracy: 0.9905 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0164 - accuracy: 0.9905 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0160 - accuracy: 0.9905 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0168 - accuracy: 0.9905 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9905 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0153 - accuracy: 0.9905 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0177 - accuracy: 0.9905 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 0.9905 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.9905 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.8165e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9778\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9778\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.7431e-04 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.7961e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.5769e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 9.2831e-04 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.2684e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.4126e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.2414e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.2541e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.1469e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.0567e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.9322e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.8214e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.7956e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.9988e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.7480e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9778\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.1717e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9778\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.0561e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9778\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.6402e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9778\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.6572e-04 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9778\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.4906e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9778\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.4141e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9778\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.2996e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9778\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.3548e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9778\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.2328e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.0723e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.0482e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.9246e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9778\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.7998e-04 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9778\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.8374e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9778\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.7536e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9778\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.7825e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9778\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.6869e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9778\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.5719e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4859e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.5240e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.5892e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6767e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.5993e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4890e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.3470e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.2379e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9778\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4635e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9778\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.3801e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9778\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.3784e-04 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9778\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.2768e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9778\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.1189e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9778\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.1530e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9778\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.1780e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9778\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.1644e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9778\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.1781e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9778\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.0015e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9778\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.9825e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9778\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.7508e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.9015e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9778\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.8335e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9778\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.6241e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9778\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.5926e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9778\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.4370e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9778\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.4079e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.3684e-04 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9778\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.2856e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9778\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.2937e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9778\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.2960e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9778\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.2153e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9778\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.1371e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9778\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.1087e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9778\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.1198e-04 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9778\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.0683e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9778\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.0937e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9778\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.0585e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9778\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.0036e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9778\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.0168e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9778\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.9996e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9778\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.9583e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9778\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.9689e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9778\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.8901e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9778\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.8346e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9778\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7489e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9778\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7184e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9778\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.6593e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9778\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.6328e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.7108e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.6309e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.5782e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9778\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.5195e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9778\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.4947e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9778\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.4866e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9778\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.4650e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9778\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.4293e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9778\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.4048e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9778\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.3509e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9778\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.3580e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9778\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.3427e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9778\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.2995e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9778\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.3058e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9778\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.3514e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9778\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.2998e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9778\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.2143e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9778\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.1528e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9778\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.1638e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9778\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.1263e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9778\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.0720e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9778\n",
      "Epoch 614/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.0418e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9778\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 5.0422e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9778\n",
      "Epoch 616/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.0053e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.0288e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.0147e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9778\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.9404e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9778\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.9098e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9778\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.9629e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9778\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.7462e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9778\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.1329e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9778\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.0806e-04 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9778\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.2350e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9778\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.0413e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.8508e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9778\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.7307e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9778\n",
      "Epoch 629/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.7193e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9778\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.7023e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9778\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.6662e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9778\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.5896e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9778\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.6801e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9778\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.5756e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9778\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.5239e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9778\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.5616e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9778\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.5254e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9778\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.4451e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9778\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.3984e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.3762e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9778\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.3162e-04 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9778\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.4713e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9778\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.5301e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9778\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.4904e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9778\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.4078e-04 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9778\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.3113e-04 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9778\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.2207e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9778\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.2428e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9778\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.2321e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9778\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.3329e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9778\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.2330e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9778\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.1159e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9778\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.0914e-04 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9778\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.1126e-04 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9778\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.0952e-04 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9778\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.1199e-04 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9778\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.1073e-04 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9778\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.0695e-04 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9778\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.0116e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9778\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.9376e-04 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9778\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.9624e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9778\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.9595e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9778\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.9385e-04 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9778\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.8673e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9778\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.8425e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.8126e-04 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9778\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.8119e-04 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9778\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.7254e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9778\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.8903e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9778\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.8835e-04 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9778\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.8449e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9778\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.7174e-04 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9778\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.6560e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9778\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.6281e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9778\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.7655e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9778\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.7735e-04 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9778\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.6033e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9778\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.7038e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.6569e-04 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9778\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.6365e-04 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9778\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.6021e-04 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9778\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.5625e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.5267e-04 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9778\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.4749e-04 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9778\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.4428e-04 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9778\n",
      "Epoch 686/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.4272e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9778\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.4044e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9778\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 3.4092e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9778\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.3372e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9778\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.3611e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9778\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.3742e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.3524e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
      "Epoch 693/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.3137e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9778\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.2783e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.2614e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9778\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.2547e-04 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9778\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.2651e-04 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9778\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.3188e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9778\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.3080e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9778\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.3312e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9778\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.2977e-04 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9778\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.2482e-04 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9778\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1873e-04 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9778\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1500e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.1433e-04 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9778\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1648e-04 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9778\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1147e-04 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9778\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1111e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9778\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1022e-04 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9778\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.0534e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9778\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0299e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9778\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.0234e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
      "Epoch 713/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9721e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9778\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9642e-04 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9778\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0560e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9778\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.0707e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9778\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0420e-04 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9778\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9972e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9778\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9530e-04 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9778\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9178e-04 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9778\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8990e-04 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9778\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8831e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9778\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8721e-04 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9778\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8661e-04 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9778\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8484e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9778\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8636e-04 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9778\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7783e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9778\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8700e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9778\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0112e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9778\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0036e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9778\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.9305e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9778\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8281e-04 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7727e-04 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9778\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7106e-04 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9778\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7256e-04 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9778\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7440e-04 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7397e-04 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7323e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7573e-04 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9778\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7363e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9778\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.7087e-04 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9778\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6694e-04 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9778\n",
      "Epoch 743/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6670e-04 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.6413e-04 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9778\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.5869e-04 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9778\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.5889e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9778\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.5776e-04 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9778\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.5668e-04 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9778\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5436e-04 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5792e-04 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9778\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5014e-04 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9778\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.5127e-04 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9778\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5116e-04 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9778\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4837e-04 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9778\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4744e-04 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9778\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4647e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9778\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.4728e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9778\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4734e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9778\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4705e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9778\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.4695e-04 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9778\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4433e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9778\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.4354e-04 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9778\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.4188e-04 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9778\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.4084e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9778\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.3952e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9778\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4068e-04 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9778\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3804e-04 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9778\n",
      "Epoch 768/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.3407e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9778\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.3715e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9778\n",
      "Epoch 770/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3727e-04 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9778\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.3816e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9778\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.3181e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9778\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3106e-04 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9778\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.3084e-04 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9778\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.2849e-04 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9778\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.2511e-04 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9778\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.2306e-04 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9778\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.2180e-04 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9778\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.2205e-04 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9778\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.1903e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9778\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.1962e-04 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9778\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.2134e-04 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9778\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.2120e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9778\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.2003e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9778\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.1995e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9778\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1805e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9778\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.1642e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9778\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.1307e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9778\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0982e-04 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9778\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.1258e-04 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9778\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.1316e-04 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9778\n",
      "Epoch 792/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.1301e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9778\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.1200e-04 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9778\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0977e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 795/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0870e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9778\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.0660e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9778\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.0741e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9778\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0294e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9778\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0251e-04 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9778\n",
      "Epoch 800/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.0283e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9778\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0129e-04 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9778\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0051e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9778\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0165e-04 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9778\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.9784e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9778\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0078e-04 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9778\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0161e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9778\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0045e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9778\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.9914e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9778\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.9674e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9778\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.9550e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9778\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.9470e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9778\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.9128e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9778\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.9573e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9778\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.9353e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9778\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.9034e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9778\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.8904e-04 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9778\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.8772e-04 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9778\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.8942e-04 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.8883e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9778\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.8891e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9778\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.8589e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9778\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.8539e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9778\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.8324e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9778\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.8250e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9778\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.8115e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9778\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.8091e-04 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9778\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.7979e-04 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9778\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7992e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7882e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9778\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7764e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9778\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7886e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9778\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7738e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9778\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.7725e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9778\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7880e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9778\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7738e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9778\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7491e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9778\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7442e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9778\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7339e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9778\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.7222e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9778\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7355e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.7195e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9778\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.7029e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9778\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6983e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9778\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6867e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
      "Epoch 845/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6944e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9778\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6865e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9778\n",
      "Epoch 847/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6950e-04 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9778\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6847e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9778\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6679e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9778\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6534e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6463e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9778\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6510e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9778\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6327e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9778\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6329e-04 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9778\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6410e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9778\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6240e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9778\n",
      "Epoch 857/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.5932e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9778\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6159e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9778\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6475e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9778\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6752e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9778\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6449e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9778\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6136e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9778\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.6083e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9778\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.5608e-04 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9778\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.5712e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9778\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5666e-04 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9778\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.5466e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9778\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5414e-04 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9778\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5411e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9778\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5264e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9778\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5145e-04 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9778\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.5100e-04 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9778\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5098e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9778\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5045e-04 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9778\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5041e-04 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9778\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4959e-04 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9778\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4906e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9778\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4795e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9778\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4741e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9778\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.4664e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4653e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9778\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4577e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9778\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.4534e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9778\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4689e-04 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9778\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4538e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9778\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.4429e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4373e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9778\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4372e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9778\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4555e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9778\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4201e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9778\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4001e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9778\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.3997e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9778\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.3959e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9778\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4229e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9778\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.3969e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9778\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.3902e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9778\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.3887e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9778\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4263e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9778\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4116e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9778\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.4058e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9778\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.3789e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9778\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3552e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9778\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3438e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9778\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3417e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9778\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3349e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9778\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3286e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3243e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9778\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3243e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9778\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3223e-04 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9778\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3268e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9778\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.3348e-04 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9778\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3386e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9778\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3293e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9778\n",
      "Epoch 914/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3144e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9778\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2889e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9778\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.2945e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9778\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2760e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9778\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2731e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9778\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2642e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9778\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2677e-04 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9778\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.2576e-04 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9778\n",
      "Epoch 922/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2517e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9778\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2435e-04 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9778\n",
      "Epoch 924/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2456e-04 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9778\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2457e-04 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9778\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2443e-04 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9778\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2351e-04 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9778\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2116e-04 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9778\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2163e-04 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9778\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9778\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2304e-04 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9778\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2280e-04 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9778\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2256e-04 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9778\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2073e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9778\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.1930e-04 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9778\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1850e-04 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9778\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1757e-04 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9778\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2015e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9778\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1670e-04 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9778\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1568e-04 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9778\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1592e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9778\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.1601e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9778\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1616e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9778\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1485e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9778\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1393e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9778\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1323e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9778\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.1239e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9778\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1314e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9778\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1269e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9778\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1049e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9778\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1044e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9778\n",
      "Epoch 952/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.1042e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9778\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0973e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9778\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0848e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9778\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0759e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9778\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0747e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9778\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0626e-04 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9778\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0642e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9778\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0621e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9778\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0568e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9778\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0484e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9778\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0433e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0406e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9778\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0338e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9778\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0350e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0253e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0202e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0185e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0198e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9778\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0136e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9778\n",
      "Epoch 971/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0131e-04 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9778\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0030e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9778\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 9.9424e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9778\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0068e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0022e-04 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9778\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 9.9185e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9778\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.8831e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9778\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.8417e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9778\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.8787e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9778\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.7608e-05 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9778\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.7149e-05 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.6365e-05 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9778\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.6359e-05 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9778\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.5891e-05 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9778\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.5435e-05 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9778\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.5641e-05 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9778\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.5081e-05 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9778\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.5022e-05 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9778\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.4116e-05 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9778\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.4329e-05 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9778\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.3403e-05 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9778\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.2920e-05 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9778\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.2667e-05 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9778\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 9.2584e-05 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9778\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.1729e-05 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.2613e-05 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9778\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.2127e-05 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9778\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.1387e-05 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9778\n",
      "Epoch 999/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.0830e-05 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9778\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.0682e-05 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=1000, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5e702",
   "metadata": {},
   "source": [
    "Here, we define a sequential neural network model using Keras. We add 3 dense layers with 64, 32, and 16 neurons each, respectively, and use the rectified linear unit (ReLU) activation function. We also add a final dense layer with 3 neurons for output using the softmax activation function(this activation function is used for multiclass problems). \n",
    "The model is also compiled using the Adam optimizer and categorical cross-entropy loss function.\n",
    "\n",
    "We then fit the model on the training data for 100 epochs with a batch size of 32. We also evaluate the model on the testing data using the validation_data parameter and accuracy as a metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b506c",
   "metadata": {},
   "source": [
    "### Compute and plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "806f31e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'True labels')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f5395",
   "metadata": {},
   "source": [
    "Here, we predict the classes for the testing data and calculate the confusion matrix to evaluate the performance of our model. We then use the seaborn library to plot the confusion matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017132a8",
   "metadata": {},
   "source": [
    "### Plot the residual, training and testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e42a377c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb7e33",
   "metadata": {},
   "source": [
    "In this step, we plot the model loss and accuracy for both training and testing data. This helps us to understand how well our model is performing on both datasets and whether the model is overfitting or not. We can adjust the number of epochs or the model architecture to improve the performance.\n",
    "\n",
    "Overall, this code provides a good starting point for a classification problem using Scikit-learn and Keras. It includes all the necessary steps, such as preprocessing, model definition, training, evaluation, and visualization. However, you may need to adjust some parameters based on your specific problem or dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b0c3ec",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbc0bd",
   "metadata": {},
   "source": [
    "1. Try different number of hidden layers, number of neurons and changing the activation function\n",
    "2. Plot the residual, training and testing error.\n",
    "3. Report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b1b60",
   "metadata": {},
   "source": [
    "### 1) Implement a neural network model with 3 hidden layers using activation function: relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=1000, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6a6bc",
   "metadata": {},
   "source": [
    "### Compute and plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1105a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "# Calculate mean squared errors\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb56e07",
   "metadata": {},
   "source": [
    "### Plot the residual, training and testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8392acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2671321",
   "metadata": {},
   "source": [
    "### 2) Implement a neural network model with 3 hidden layers using the tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a31bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='tanh', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1e448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3c60e95",
   "metadata": {},
   "source": [
    "Here, I define a sequential neural network model with 5 hidden layers as opposed to the previous models.\n",
    "The hidden layers consist of 128, 64 32, 16 and 10 neurons respectively with each using the Sigmoid activation function. \n",
    "There is also a final dense layer with a single neuron for output. The model is compiled using the Adam optimizer and mean squared error (MSE) loss function.\n",
    "\n",
    "The parameters for fitting the training data include:\n",
    "- 100 epochs \n",
    "- batch size of 32 (for each epoch, we feed the data into the model by iterating through the data (X_train.shape[0] / 32) times\n",
    "\n",
    "We also evaluate the model on the testing data using the validation_data parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160741fa",
   "metadata": {},
   "source": [
    "#### Evaluate the performance of the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Training Mean Squared Error: \", mse_train)\n",
    "print(\"Testing Mean Squared Error: \", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798175a4",
   "metadata": {},
   "source": [
    "### 3) Implement a neural network model with 3 hidden layers using the Sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3869e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3834b0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b61a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
